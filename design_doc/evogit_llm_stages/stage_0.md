# Project Guideline: LLM-Guided Bin Packing Solver

At this stage, focus on building the overall codebase and completing each project component.

## Objective

The objective of this project is to explore the use of large language models (LLMs) to **automatically generate high-quality solvers** for the classic **bin-packing problem**. This research evaluates the generated solvers by testing them using a standardized evaluation function, focusing on both **correctness** and **efficiency**.

---

## Problem Description

The **bin-packing problem** is an NP-hard combinatorial optimization task. Given a set of items (each with a weight between 0 and 1), the task is to pack them into a **minimum number of bins**, where each bin has a fixed capacity of 1 and cannot exceed this limit.

In this project:

* Each **item** is a float `0 < weight < 1`.
* Each **bin** has a **capacity of 1**.
* The goal is to **minimize the total number of bins used**.

---

## Function Signatures

### Problem Instance Generation

You could write better docstrings than the ones below.

```python
def generate_instance(n: int) -> list[float]:
    """
    Generate a random instance of the bin-packing problem.

    Parameters:
        n: Number of items to generate.

    Returns:
        A list of floats representing item weights (0 < weight < 1).
    """
    pass
```

### Evaluator Function

```python
def evaluate(solution: str) -> float:
    """
    Evaluate a candidate solution produced by the LLM.

    Parameters:
        solution: A string of Python code representing a bin-packing algorithm.

    Returns:
        A float score where lower values indicate better solutions.
        Invalid or error-prone code should return a high penalty score.
    """
    pass
```

### Solver Function

```python
def solve(items: list[float], budget: int) -> list[int]:
    """
    Use the LLM and evaluator to generate and test a solution within a time budget.

    Parameters:
        items: A list of floats representing item weights.
        budget: Time limit in milliseconds for finding a solution.

    Returns:
        A list of integers representing the bin index assignment for each item.
    """
    pass
```

### Algorithm Class

```python
from typing import Any


class Algorithm:
    def __init__(self, population_size: int, budget: int, llm_client: Any):
        """
        Initialize the evolutionary search process for generating and refining solutions.
        """
        pass

    def step(self):
        """
        Run one iteration of the optimization loop: generate, evaluate, and select solutions.
        """
        pass

    def get_best_solution(self) -> str:
        """
        Retrieve the best performing solution seen so far.

        Returns:
            A string representing the best Python code solution.
        """
        pass
```

### Prompt Generation

```python
def generate_prompt() -> str:
    """
    Generate a prompt for the LLM to produce bin-packing solutions.

    Returns:
        A string containing the prompt template.
    """
    pass
```

---

## LLM Integration

The project uses the Azure OpenAI SDK for LLM interaction. The initial setup is in `main.py`, which loads environment variables (`API_KEY` and `ENDPOINT`), configures the API client, and initializes the LLM.

Basic usage to call the LLM:

```python
response = llm_client.complete(
    messages=[
        UserMessage(content="Write a function that solves the bin-packing problem..."),
    ],
)
text_output = response.choices[0].message.content
```

Be sure to sanitize and validate the output, as the LLM may occasionally return syntactically incorrect or logically invalid code.

---

## Project Structure

These important modules are mandatory for the project:
main.py # Entry point: runs the full pipeline and prints final solution
problem.py # Problem instance generation
evaluator.py # Code evaluator logic
algorithm.py # Optimization loop logic
prompt.py # LLM prompt templates

You are encouraged to modularize your work, by written additional modules when needed. Each major class or function should reside in its own file, named after the class or function.

---

## Experiment Settings

* Iterations: 10 outer-loop steps
* Population Size: 16 candidate solutions per iteration
* Evaluation Budget: 1000 milliseconds per solver evaluation

At each iteration, the algorithm:

1. Calls the LLM to generate a population of candidate solver programs, ideally an improved version of the generated code. Candidate solutions are generated by the LLM through single or multi-turn interactions.
2. Evaluates each solver using the evaluator.
3. Selects the best solutions to seed the next iteration.

---

## Additional Notes

* Robustness: The system should gracefully handle:

  * LLM API failures, timeouts, or null responses.
  * Invalid or broken Python code returned by the LLM.
  * Code that violates the bin-packing constraints.

* Time Limits: The `bin_packing_solver` function must strictly respect the time budget. You may need to implement a mechanism to interrupt the function if it exceeds the allowed time, such as using threading or multiprocessing, signals, etc.

* Prompt Engineering: Design effective prompts to guide the LLM in generating valid, interpretable outputs and performant code. Store prompt templates in `prompt.py`.

* Dynamic Code Loading: Since the project involves executing code generated by the LLM, you may need to use `exec` or similar mechanisms to dynamically load and run the generated Python code. In such cases, the exact function names may not be known ahead of time, which can cause static analysis tools like Pyright to raise errors. To suppress these errors for specific lines, you can append `# pyright: ignore` at the end of the affected line.

---

## Python Environment

Python 3.13 is used for this project.
Only use built-in Python libraries, except for the Azure OpenAI SDK.
